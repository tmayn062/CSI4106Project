{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"tensorflow_hub>=0.6.0\"\n",
    "# !pip install \"tensorflow>=2.0.0\"\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo = hub.KerasLayer(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def elmo_vectors(x):\n",
    "#   embeddings = elmo(x.tolist())\n",
    "#   with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(tf.tables_initializer())\n",
    "#     # return average of ELMo features\n",
    "#     return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['talesfromtechsupport' 'teenmom' 'Harley' 'ringdoorbell' 'intel'\n",
      " 'residentevil' 'BATProject' 'hockeyplayers' 'asmr' 'rawdenim'\n",
      " 'steinsgate' 'DBZDokkanBattle' 'Nootropics' 'l5r' 'NameThatSong'\n",
      " 'homeless' 'antidepressants' 'absolver' 'KissAnime' 'sissyhypno'\n",
      " 'oculusnsfw' 'dpdr' 'Garmin' 'AskLiteraryStudies' 'poetry_critics'\n",
      " 'skiing' 'shrimptank' 'logorequests' 'Stargate' 'foreskin_restoration'\n",
      " 'sharepoint' 'synthesizers' 'gravityfalls' 'androiddev' 'Grimdawn'\n",
      " 'driving' 'FORTnITE' 'dndnext' 'Magic' 'MtvChallenge' 'FoWtcg'\n",
      " 'harrypotter' 'TryingForABaby' 'sewing' 'foxholegame' 'madmen'\n",
      " 'JUSTNOMIL' 'APStudents' 'sharditkeepit' 'amateurradio' 'sleeptrain'\n",
      " 'fatpeoplestories' 'GameStop' 'scuba' 'Firefighting' 'Mustang'\n",
      " 'riverdale' 'flying' 'bartenders' 'scooters' 'trumpet' 'projecteternity'\n",
      " 'musictheory' 'factorio' 'SexToys' 'EternalCardGame' 'PLC' 'sailing'\n",
      " 'Mattress' 'climbing' 'uberdrivers' 'Cloud9' 'csharp' 'communism101'\n",
      " 'windowsphone']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"rspct.tsv\", sep='\\t')\n",
    "print(df.subreddit.unique()[0:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000\n"
     ]
    }
   ],
   "source": [
    "df.head\n",
    "df = df.loc[df['subreddit'].isin(df.subreddit.unique()[0:75])]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              id             subreddit  \\\n",
       "0        6d8knd  talesfromtechsupport   \n",
       "1        58mbft               teenmom   \n",
       "2        8f73s7                Harley   \n",
       "3        6ti6re          ringdoorbell   \n",
       "4        77sxto                 intel   \n",
       "...         ...                   ...   \n",
       "1012903  6upjxk                 Magic   \n",
       "1012932  8jmd1s           foxholegame   \n",
       "1012946  6z7i2o                Cloud9   \n",
       "1012949  6b7qlf         hockeyplayers   \n",
       "1012983  5ofxmn               teenmom   \n",
       "\n",
       "                                                     title  \\\n",
       "0                   Remember your command line switches...   \n",
       "1                          So what was Matt \"addicted\" to?   \n",
       "2                                           No Club Colors   \n",
       "3              Not door bell, but floodlight mount height.   \n",
       "4        Worried about my 8700k small fft/data stress r...   \n",
       "...                                                    ...   \n",
       "1012903  Noob question, Recommendations for beginner kits.   \n",
       "1012932                            Put Field MG inside APC   \n",
       "1012946                Crossing the Gauntlet: 2017 edition   \n",
       "1012949  Would switching to sharper hollow help me with...   \n",
       "1012983  Something that frustrates me when Leah/Ali is ...   \n",
       "\n",
       "                                                  selftext  \n",
       "0        Hi there,  <lb>The usual. Long time lerker, fi...  \n",
       "1        Did he ever say what his addiction was or is h...  \n",
       "2        Funny story. I went to college in Las Vegas. T...  \n",
       "3        I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4        Prime95 (regardless of version) and OCCT both,...  \n",
       "...                                                    ...  \n",
       "1012903  I am a long time fan of magic, but i am fairly...  \n",
       "1012932  In the _World Conquest_ mode the Field MG has ...  \n",
       "1012946  Inspired by the works of /u/sayntclair and /u/...  \n",
       "1012949  Im 6'0 290lb beginner currently using a 3/4 ho...  \n",
       "1012983  I lurk here a lot and people seem to view Ali ...  \n",
       "\n",
       "[75000 rows x 4 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook\n",
    "# reddit_posts = [df[i:i+1000] for i in range(0,df.shape[0],1000)]\n",
    "# title_embeddings =[]\n",
    "# import pickle\n",
    "\n",
    "# for i in tqdm_notebook(reddit_posts):\n",
    "# #     print(i['title'].tolist())\n",
    "#     tensor = tf.convert_to_tensor(\n",
    "#         i['title'].tolist(),\n",
    "#         dtype=None,\n",
    "#         dtype_hint=None,\n",
    "#         name=None\n",
    "#     )\n",
    "#     title_embeddings.append(elmo(tensor))\n",
    "#     with open('redd_tittle.pickle', 'wb') as f:\n",
    "#         pickle.dump(title_embeddings, f)\n",
    "# print(title_embeddings)\n",
    "# # print() \n",
    "# # elmo_title_vecs = [elmo_vectors(x['title']) for x in tqdm(df.iloc[0:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_text_embeddings =[]\n",
    "# import pickle\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# reddit_posts = [df[i:i+100] for i in range(0,df.shape[0],100)]\n",
    "# post_text_embeddings = []\n",
    "# for i in tqdm_notebook(reddit_posts):\n",
    "#     tensor = tf.convert_to_tensor(\n",
    "#         i['selftext'].tolist(),\n",
    "#         dtype=None,\n",
    "#         dtype_hint=None,\n",
    "#         name=None\n",
    "#     )\n",
    "#     post_text_embeddings.append(elmo(tensor))\n",
    "#     with open('redd_self_text.pickle', 'wb') as f:\n",
    "#         pickle.dump(post_text_embeddings, f)\n",
    "# print(post_text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Hellp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "75000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "infile = open('redd_tittle.pickle','rb')\n",
    "arr = pickle.load(infile)\n",
    "print(len(arr))\n",
    "infile.close()\n",
    "\n",
    "import numpy as np\n",
    "elmo_title_vecs_new = np.concatenate(arr, axis = 0)\n",
    "print(len(elmo_title_vecs_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_title, test_title, train_subreddit, test_subreddit = train_test_split(elmo_title_vecs_new,\n",
    "                                                                      df[\"subreddit\"],\n",
    "                                                                      test_size=0.1, \n",
    "                                                                      random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train_title.head\n",
    "# train_subreddit.head\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(train_title, train_subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4945333333333333\n"
     ]
    }
   ],
   "source": [
    "preds_valid = lreg.predict(test_title)\n",
    "correct = 0\n",
    "for actual, pred in zip(test_subreddit, preds_valid):\n",
    "  if actual == pred:\n",
    "    correct = correct + 1\n",
    "print(correct/len(test_subreddit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(lreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.pickle', 'wb') as f:\n",
    "    pickle.dump(preds_valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskLiteraryStudies': 121, 'l5r': 91, 'Garmin': 112, 'sewing': 103, 'fatpeoplestories': 97, 'MtvChallenge': 109, 'Harley': 88, 'PLC': 96, 'Mustang': 86, 'bartenders': 98, 'amateurradio': 93, 'Cloud9': 109, 'csharp': 87, 'oculusnsfw': 116, 'gravityfalls': 88, 'scuba': 86, 'FoWtcg': 108, 'BATProject': 93, 'hockeyplayers': 99, 'androiddev': 124, 'trumpet': 91, 'EternalCardGame': 77, 'JUSTNOMIL': 112, 'Stargate': 81, 'Nootropics': 107, 'Mattress': 115, 'teenmom': 106, 'sleeptrain': 95, 'foxholegame': 87, 'musictheory': 113, 'poetry_critics': 103, 'TryingForABaby': 98, 'DBZDokkanBattle': 102, 'talesfromtechsupport': 107, 'Firefighting': 83, 'projecteternity': 86, 'riverdale': 99, 'madmen': 100, 'synthesizers': 92, 'climbing': 95, 'uberdrivers': 97, 'Magic': 109, 'APStudents': 107, 'sailing': 100, 'driving': 112, 'shrimptank': 109, 'windowsphone': 89, 'steinsgate': 123, 'rawdenim': 103, 'homeless': 116, 'foreskin_restoration': 94, 'sharditkeepit': 98, 'ringdoorbell': 95, 'residentevil': 95, 'antidepressants': 103, 'Grimdawn': 109, 'flying': 89, 'communism101': 84, 'KissAnime': 95, 'asmr': 107, 'absolver': 91, 'logorequests': 95, 'factorio': 107, 'dpdr': 125, 'sissyhypno': 92, 'scooters': 100, 'dndnext': 100, 'harrypotter': 96, 'sharepoint': 129, 'GameStop': 103, 'SexToys': 97, 'FORTnITE': 65, 'skiing': 88, 'intel': 103, 'NameThatSong': 122}\n",
      "K-Precision at k =1\n",
      "0.5785123966942148\n",
      "K-Precision at k =3\n",
      "0.5061728395061729\n",
      "K-Precision at k =5\n",
      "0.8523076923076923\n"
     ]
    }
   ],
   "source": [
    "counter_dict = {}\n",
    "for pred in preds_valid:\n",
    "    if pred in counter_dict:\n",
    "        counter_dict[pred] = counter_dict[pred] +1\n",
    "    else:\n",
    "        counter_dict[pred] = 1\n",
    "print(counter_dict)\n",
    "\n",
    "print(\"K-Precision at k =1\")\n",
    "k1Counter = 0\n",
    "k1CorrectCounter = 0\n",
    "for actual, pred in zip(test_subreddit, preds_valid):\n",
    "    if pred == 'AskLiteraryStudies':\n",
    "        k1Counter = k1Counter + 1\n",
    "        if pred == actual:\n",
    "            k1CorrectCounter = k1CorrectCounter + 1\n",
    "print(k1CorrectCounter/k1Counter)\n",
    "\n",
    "\n",
    "print(\"K-Precision at k =3\")\n",
    "k3Counter = 0\n",
    "k3CorrectCounter = 0\n",
    "for actual, pred in zip(test_subreddit, preds_valid):\n",
    "    if pred == 'AskLiteraryStudies' or pred == 'l5r' or pred == 'Garmin':\n",
    "        k3Counter = k3Counter + 1\n",
    "        if pred == actual:\n",
    "            k3CorrectCounter = k3CorrectCounter + 1\n",
    "print(k3CorrectCounter/k3Counter)\n",
    "\n",
    "print(\"K-Precision at k =5\")\n",
    "k5Counter = 0\n",
    "k5CorrectCounter = 0\n",
    "for actual, pred in zip(test_subreddit, preds_valid):\n",
    "    if pred in ['AskLiteraryStudies', 'l5r', 'Garmin', 'sewing', 'fatpeoplestories']:\n",
    "        k5Counter = k3Counter + 1\n",
    "        if pred == actual:\n",
    "            k5CorrectCounter = k5CorrectCounter + 1\n",
    "print(k5CorrectCounter/k5Counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
