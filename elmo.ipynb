{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "config = Config(\n",
    "    testing=True,\n",
    "    seed=1,\n",
    "    #changed from 64\n",
    "    batch_size=48,\n",
    "    lr=3e-4,\n",
    "    epochs=2,\n",
    "    hidden_sz=64,\n",
    "    max_seq_len=100, # necessary to limit memory usage\n",
    "    max_vocab_size=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common.checks import ConfigurationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/reddit-selfposts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed manually to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f27080bd190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reddit-selfposts/rspct.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs=df[\"subreddit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['talesfromtechsupport',\n",
       " 'teenmom',\n",
       " 'Harley',\n",
       " 'ringdoorbell',\n",
       " 'intel',\n",
       " 'residentevil',\n",
       " 'BATProject',\n",
       " 'hockeyplayers',\n",
       " 'asmr',\n",
       " 'rawdenim',\n",
       " 'steinsgate',\n",
       " 'DBZDokkanBattle',\n",
       " 'Nootropics',\n",
       " 'l5r',\n",
       " 'NameThatSong',\n",
       " 'homeless',\n",
       " 'antidepressants',\n",
       " 'absolver',\n",
       " 'KissAnime',\n",
       " 'sissyhypno',\n",
       " 'oculusnsfw',\n",
       " 'dpdr',\n",
       " 'Garmin',\n",
       " 'AskLiteraryStudies',\n",
       " 'poetry_critics',\n",
       " 'skiing',\n",
       " 'shrimptank',\n",
       " 'logorequests',\n",
       " 'Stargate',\n",
       " 'foreskin_restoration',\n",
       " 'sharepoint',\n",
       " 'synthesizers',\n",
       " 'gravityfalls',\n",
       " 'androiddev',\n",
       " 'Grimdawn',\n",
       " 'driving',\n",
       " 'FORTnITE',\n",
       " 'dndnext',\n",
       " 'Magic',\n",
       " 'MtvChallenge',\n",
       " 'FoWtcg',\n",
       " 'harrypotter',\n",
       " 'TryingForABaby',\n",
       " 'sewing',\n",
       " 'foxholegame',\n",
       " 'madmen',\n",
       " 'JUSTNOMIL',\n",
       " 'APStudents',\n",
       " 'sharditkeepit',\n",
       " 'amateurradio',\n",
       " 'sleeptrain',\n",
       " 'fatpeoplestories',\n",
       " 'GameStop',\n",
       " 'scuba',\n",
       " 'Firefighting',\n",
       " 'Mustang',\n",
       " 'riverdale',\n",
       " 'flying',\n",
       " 'bartenders',\n",
       " 'scooters',\n",
       " 'trumpet',\n",
       " 'projecteternity',\n",
       " 'musictheory',\n",
       " 'factorio',\n",
       " 'SexToys',\n",
       " 'EternalCardGame',\n",
       " 'PLC',\n",
       " 'sailing',\n",
       " 'Mattress',\n",
       " 'climbing',\n",
       " 'uberdrivers',\n",
       " 'Cloud9',\n",
       " 'csharp',\n",
       " 'communism101',\n",
       " 'windowsphone',\n",
       " 'AskAnthropology',\n",
       " 'secretsanta',\n",
       " 'Volkswagen',\n",
       " 'BigBrother',\n",
       " 'osugame',\n",
       " 'spartanrace',\n",
       " 'needforspeed',\n",
       " 'Cruise',\n",
       " 'blackmirror',\n",
       " 'China',\n",
       " 'resumes',\n",
       " 'homeassistant',\n",
       " 'starcraft',\n",
       " 'Cubers',\n",
       " 'Warframe',\n",
       " 'Professors',\n",
       " 'parrots',\n",
       " 'TOR',\n",
       " 'AvPD',\n",
       " 'Landlord',\n",
       " 'WhiteWolfRPG',\n",
       " 'DBS_CardGame',\n",
       " 'atheism',\n",
       " 'buffy',\n",
       " 'Shoplifting',\n",
       " 'reddeadredemption',\n",
       " 'germany',\n",
       " 'Schizoid',\n",
       " 'Nanny',\n",
       " 'WWEChampions',\n",
       " 'MMA',\n",
       " 'MSLGame',\n",
       " 'French',\n",
       " 'cosplay',\n",
       " 'sugarlifestyleforum',\n",
       " 'PHPhelp',\n",
       " 'WarhammerCompetitive',\n",
       " 'Iota',\n",
       " 'CryptoKitties',\n",
       " 'snakes',\n",
       " 'securityguards',\n",
       " 'Hue',\n",
       " 'Costco',\n",
       " 'IASIP',\n",
       " 'tacobell',\n",
       " 'jewelry',\n",
       " 'EmulationOnAndroid',\n",
       " 'Rabbits',\n",
       " 'thesims',\n",
       " 'dresdenfiles',\n",
       " 'Hunting',\n",
       " 'MoviePassClub',\n",
       " 'TowerofGod',\n",
       " 'Allergies',\n",
       " 'snapchat',\n",
       " 'nanocurrency',\n",
       " 'Veterans',\n",
       " 'CaptainTsubasaDT',\n",
       " 'Anarchism',\n",
       " 'indonesia',\n",
       " 'horror',\n",
       " 'malaysia',\n",
       " 'theydidthemath',\n",
       " 'fleshlight',\n",
       " 'AcademicPsychology',\n",
       " 'productivity',\n",
       " 'LinkinPark',\n",
       " 'fatestaynight',\n",
       " 'kucoin',\n",
       " 'excel',\n",
       " 'tea',\n",
       " 'turning',\n",
       " 'UnresolvedMysteries',\n",
       " 'diabetes',\n",
       " 'eczema',\n",
       " 'whatsthisworth',\n",
       " 'westworld',\n",
       " 'thewalkingdead',\n",
       " 'docker',\n",
       " 'xxfitness',\n",
       " 'emojipasta',\n",
       " 'synology',\n",
       " 'puppy101',\n",
       " 'Libraries',\n",
       " 'dji',\n",
       " 'survivor',\n",
       " 'muacjdiscussion',\n",
       " 'GMAT',\n",
       " 'DunderMifflin',\n",
       " 'bigboobproblems',\n",
       " 'LDESurvival',\n",
       " 'discgolf',\n",
       " 'Dreams',\n",
       " 'headphones',\n",
       " 'StudentLoans',\n",
       " 'bourbon',\n",
       " 'Geosim',\n",
       " 'Plumbing',\n",
       " 'ptsd',\n",
       " 'lawschooladmissions',\n",
       " 'greysanatomy',\n",
       " 'PrettyLittleLiars',\n",
       " 'AlphaBayMarket',\n",
       " 'Snus',\n",
       " 'TheExpanse',\n",
       " 'Miscarriage',\n",
       " 'Eve',\n",
       " 'uscg',\n",
       " 'fakeid',\n",
       " 'drumcorps',\n",
       " 'wacom',\n",
       " 'SonyXperia',\n",
       " 'vexillology',\n",
       " 'formula1',\n",
       " 'animation',\n",
       " 'digitalnomad',\n",
       " 'graphic_design',\n",
       " 'VisitingIceland',\n",
       " 'widowers',\n",
       " 'tabletopgamedesign',\n",
       " 'cats',\n",
       " 'RocketLeague',\n",
       " 'GirlsXBattle',\n",
       " 'techsupport',\n",
       " 'woodworking',\n",
       " 'AutoModerator',\n",
       " 'yandere_simulator',\n",
       " 'ABraThatFits',\n",
       " 'HotPeppers',\n",
       " 'yoga',\n",
       " 'hookah',\n",
       " 'guitars',\n",
       " 'weddingplanning',\n",
       " 'biology',\n",
       " 'PlasticSurgery',\n",
       " 'obs',\n",
       " 'GodofWar',\n",
       " 'AstralProjection',\n",
       " 'malehairadvice',\n",
       " 'TalesFromThePizzaGuy',\n",
       " 'boxoffice',\n",
       " 'kingdomcome',\n",
       " 'TheSimpsons',\n",
       " 'beards',\n",
       " 'volleyball',\n",
       " 'tarot',\n",
       " 'Epilepsy',\n",
       " 'italy',\n",
       " 'SiliconValleyHBO',\n",
       " 'codes',\n",
       " 'TokyoGhoul',\n",
       " 'pregnant',\n",
       " 'badroommates',\n",
       " 'Ghosts',\n",
       " 'redditdev',\n",
       " 'DestructiveReaders',\n",
       " 'Shadowverse',\n",
       " 'Nest',\n",
       " 'vmware',\n",
       " 'foreignservice',\n",
       " 'Kava',\n",
       " 'Parahumans',\n",
       " 'cycling',\n",
       " 'knifeclub',\n",
       " 'MBA',\n",
       " 'Lexus',\n",
       " 'rails',\n",
       " 'adventuretime',\n",
       " 'cancer',\n",
       " 'Naruto',\n",
       " 'WayfarersPub',\n",
       " 'lacrosse',\n",
       " 'Fencing',\n",
       " 'csshelp',\n",
       " 'DigimonLinkz',\n",
       " 'Meditation',\n",
       " 'genderqueer',\n",
       " 'aznidentity',\n",
       " 'shortscarystories',\n",
       " 'zootopia',\n",
       " 'volt',\n",
       " 'churning',\n",
       " 'starbucks',\n",
       " 'Rowing',\n",
       " 'lifeisstrange',\n",
       " 'lawofattraction',\n",
       " 'Lineage2Revolution',\n",
       " 'drums',\n",
       " 'Tekken',\n",
       " 'awardtravel',\n",
       " 'tipofmypenis',\n",
       " 'instantpot',\n",
       " 'ComicBookCollabs',\n",
       " 'sales',\n",
       " 'MaladaptiveDreaming',\n",
       " 'architecture',\n",
       " 'notebooks',\n",
       " 'FargoTV',\n",
       " 'MDMA',\n",
       " 'AndroidAuto',\n",
       " 'Breadit',\n",
       " 'Tinder',\n",
       " 'fightsticks',\n",
       " 'classicalmusic',\n",
       " 'Construction',\n",
       " 'watercooling',\n",
       " 'haskell',\n",
       " 'SteamController',\n",
       " 'vikingstv',\n",
       " 'weezer',\n",
       " 'BeardedDragons',\n",
       " 'soccer',\n",
       " 'JustUnsubbed',\n",
       " 'Magento',\n",
       " 'cfs',\n",
       " 'SkincareAddiction',\n",
       " 'Malazan',\n",
       " 'ConanExiles',\n",
       " 'Volvo',\n",
       " 'Insurance',\n",
       " 'quittingkratom',\n",
       " 'summonerswar',\n",
       " 'VoiceActing',\n",
       " 'solar',\n",
       " 'EvolveGame',\n",
       " 'camping',\n",
       " 'watch_dogs',\n",
       " 'Roku',\n",
       " 'Stormlight_Archive',\n",
       " 'AutoHotkey',\n",
       " 'Honda',\n",
       " 'git',\n",
       " 'SolidWorks',\n",
       " 'MandelaEffect',\n",
       " 'collapse',\n",
       " 'tall',\n",
       " 'duelyst',\n",
       " 'HFY',\n",
       " 'freemasonry',\n",
       " 'vertcoin',\n",
       " 'thinkpad',\n",
       " 'premiere',\n",
       " 'Undertale',\n",
       " 'hamsters',\n",
       " 'ynab',\n",
       " 'cscareerquestions',\n",
       " 'Stellar',\n",
       " 'asexuality',\n",
       " 'bladeandsoul',\n",
       " 'HollowKnight',\n",
       " 'migraine',\n",
       " 'SCP',\n",
       " 'Corsair',\n",
       " 'RWBY',\n",
       " 'flyfishing',\n",
       " 'VietNam',\n",
       " 'backpacking',\n",
       " 'tdi',\n",
       " 'Incels',\n",
       " 'lotr',\n",
       " 'django',\n",
       " 'Stoicism',\n",
       " 'Wizard101',\n",
       " 'funkopop',\n",
       " 'PCOS',\n",
       " 'MuayThai',\n",
       " 'ExNoContact',\n",
       " 'Swimming',\n",
       " 'PoloniexForum',\n",
       " 'swrpg',\n",
       " 'hiphopheads',\n",
       " 'BDSMcommunity',\n",
       " 'nin',\n",
       " 'gridcoin',\n",
       " 'civ',\n",
       " 'Standup',\n",
       " 'math',\n",
       " 'Cricket',\n",
       " 'MrRobot',\n",
       " 'ecommerce',\n",
       " 'SpaceXLounge',\n",
       " 'slp',\n",
       " 'bladerunner',\n",
       " 'MomForAMinute',\n",
       " 'unrealengine',\n",
       " 'GearsOfWar',\n",
       " 'windows',\n",
       " 'powerrangers',\n",
       " 'NASCAR',\n",
       " 'snowboarding',\n",
       " 'Kombucha',\n",
       " 'BoJackHorseman',\n",
       " 'tattoo',\n",
       " 'xxketo',\n",
       " '3d6',\n",
       " 'ABDL',\n",
       " 'LineageOS',\n",
       " 'gigantic',\n",
       " 'TheOA',\n",
       " 'thesopranos',\n",
       " 'StopGaming',\n",
       " 'netneutrality',\n",
       " 'ArcherFX',\n",
       " 'Beekeeping',\n",
       " 'shrooms',\n",
       " 'cemu',\n",
       " 'guitarpedals',\n",
       " 'Charity',\n",
       " 'bioinformatics',\n",
       " 'baseball',\n",
       " 'Fibromyalgia',\n",
       " 'misophonia',\n",
       " 'golf',\n",
       " 'lasercutting',\n",
       " 'GERD',\n",
       " 'civilengineering',\n",
       " 'Seaofthieves',\n",
       " 'Berserk',\n",
       " 'KeybaseProofs',\n",
       " 'GuitarAmps',\n",
       " 'socialskills',\n",
       " 'history',\n",
       " 'Throwers',\n",
       " 'seedboxes',\n",
       " 'TownofSalemgame',\n",
       " 'Leathercraft',\n",
       " 'btc',\n",
       " 'amazon',\n",
       " 'Saxophonics',\n",
       " 'DeadBedrooms',\n",
       " 'cinematography',\n",
       " 'OccupationalTherapy',\n",
       " 'AdobeIllustrator',\n",
       " 'pettyrevenge',\n",
       " 'MoneroMining',\n",
       " 'callofcthulhu',\n",
       " 'antiMLM',\n",
       " 'wownoob',\n",
       " 'succulents',\n",
       " 'dxm',\n",
       " 'grammar',\n",
       " 'NEO',\n",
       " 'reactjs',\n",
       " 'Judaism',\n",
       " 'ShingekiNoKyojin',\n",
       " 'StateOfDecay',\n",
       " 'stopdrinking',\n",
       " 'titanfall',\n",
       " 'lonely',\n",
       " 'Eminem',\n",
       " 'Accounting',\n",
       " 'Luthier',\n",
       " 'writing',\n",
       " 'projectmanagement',\n",
       " 'redditsync',\n",
       " 'newtothenavy',\n",
       " 'discordapp',\n",
       " 'osx',\n",
       " 'teslamotors',\n",
       " 'Tulpas',\n",
       " 'Warmachine',\n",
       " 'INeedAName',\n",
       " 'gorillaz',\n",
       " 'vaginismus',\n",
       " 'battlecats',\n",
       " 'LV426',\n",
       " 'lost',\n",
       " 'shameless',\n",
       " 'Audi',\n",
       " 'piano',\n",
       " 'canada',\n",
       " 'Physics',\n",
       " 'Testosterone',\n",
       " 'Conservative',\n",
       " 'amateur_boxing',\n",
       " 'PFSENSE',\n",
       " 'GODZILLA',\n",
       " 'homedefense',\n",
       " 'garlicoin',\n",
       " 'Kayaking',\n",
       " 'DungeonWorld',\n",
       " 'Welding',\n",
       " 'lasik',\n",
       " 'Sneakers',\n",
       " 'startrek',\n",
       " 'southafrica',\n",
       " 'askMRP',\n",
       " 'subnautica',\n",
       " 'mercedes_benz',\n",
       " 'askphilosophy',\n",
       " 'postmates',\n",
       " 'autism',\n",
       " 'Borderlands2',\n",
       " 'EnterTheGungeon',\n",
       " 'Gamingcirclejerk',\n",
       " 'OnePunchMan',\n",
       " 'Cigarettes',\n",
       " 'CreditCards',\n",
       " 'KikRoleplay',\n",
       " 'orangeisthenewblack',\n",
       " 'paintball',\n",
       " 'rust',\n",
       " 'gis',\n",
       " 'Outlook',\n",
       " 'Debate',\n",
       " 'birthcontrol',\n",
       " 'evangelion',\n",
       " 'Spanish',\n",
       " 'dyinglight',\n",
       " 'NewSkaters',\n",
       " 'burstcoin',\n",
       " 'baduk',\n",
       " 'livesound',\n",
       " 'arduino',\n",
       " 'TalesFromTheFrontDesk',\n",
       " 'ethtrader',\n",
       " 'networking',\n",
       " 'wls',\n",
       " 'TheWeeknd',\n",
       " 'Israel',\n",
       " 'msp',\n",
       " 'Wrangler',\n",
       " 'flatearth',\n",
       " 'UFOs',\n",
       " 'beer',\n",
       " 'space',\n",
       " 'reloading',\n",
       " 'arenaofvalor',\n",
       " 'latterdaysaints',\n",
       " 'learnpython',\n",
       " 'RealEstate',\n",
       " 'sonarr',\n",
       " 'rheumatoid',\n",
       " 'breakingbad',\n",
       " 'verizon',\n",
       " 'raisedbyborderlines',\n",
       " 'homestead',\n",
       " 'hamiltonmusical',\n",
       " 'furry',\n",
       " 'devops',\n",
       " 'marketing',\n",
       " 'DragonsDogma',\n",
       " 'japanlife',\n",
       " 'astrology',\n",
       " 'redesign',\n",
       " 'transformers',\n",
       " 'wicked_edge',\n",
       " 'triathlon',\n",
       " 'flexibility',\n",
       " 'MouseReview',\n",
       " '3Dprinting',\n",
       " 'HouseOfCards',\n",
       " 'dvdcollection',\n",
       " 'occult',\n",
       " 'mopeio',\n",
       " 'InstacartShoppers',\n",
       " 'Chromecast',\n",
       " 'consulting',\n",
       " 'siacoin',\n",
       " 'socialwork',\n",
       " 'PvZHeroes',\n",
       " 'littlespace',\n",
       " 'RATS',\n",
       " 'Herpes',\n",
       " 'criterion',\n",
       " 'cigars',\n",
       " 'howyoudoin',\n",
       " 'Blacksmith',\n",
       " 'Outlier',\n",
       " 'teslore',\n",
       " 'hacking',\n",
       " 'TheWire',\n",
       " 'ShieldAndroidTV',\n",
       " 'popheads',\n",
       " 'CanadaPublicServants',\n",
       " 'pinkfloyd',\n",
       " 'fairytail',\n",
       " 'kpop',\n",
       " 'araragi',\n",
       " 'hitmobile',\n",
       " 'Narcolepsy',\n",
       " 'Drama',\n",
       " 'Rapekink',\n",
       " 'oaklandraiders',\n",
       " 'Sat',\n",
       " 'savageworlds',\n",
       " 'Roll20',\n",
       " 'bisexual',\n",
       " 'shield',\n",
       " 'sociopath',\n",
       " 'smoking',\n",
       " 'dontstarve',\n",
       " 'SexWorkers',\n",
       " 'datarecovery',\n",
       " 'cassetteculture',\n",
       " 'Yugioh101',\n",
       " 'MemeEconomy',\n",
       " 'Archery',\n",
       " 'characterdrawing',\n",
       " 'walkingwarrobots',\n",
       " 'flashlight',\n",
       " 'Chefit',\n",
       " 'speedrun',\n",
       " 'subaru',\n",
       " 'belgium',\n",
       " 'modeltrains',\n",
       " 'nvidia',\n",
       " 'piercing',\n",
       " 'tableau',\n",
       " 'islam',\n",
       " 'wine',\n",
       " 'whatstheword',\n",
       " 'Monstercat',\n",
       " 'GalaxyS8',\n",
       " 'Wordpress',\n",
       " 'origin',\n",
       " 'france',\n",
       " 'ACL',\n",
       " 'Electroneum',\n",
       " 'stepparents',\n",
       " 'Denmark',\n",
       " 'Brawlhalla',\n",
       " 'rupaulsdragrace',\n",
       " 'hinduism',\n",
       " 'vandwellers',\n",
       " 'brandnew',\n",
       " 'boostedboards',\n",
       " 'AskHR',\n",
       " 'gaymers',\n",
       " 'photography',\n",
       " 'DFO',\n",
       " 'starfinder_rpg',\n",
       " 'abortion',\n",
       " '7daystodie',\n",
       " 'EliteOne',\n",
       " 'lego',\n",
       " 'NoMansSkyTheGame',\n",
       " 'German',\n",
       " 'photoshop',\n",
       " 'tasker',\n",
       " 'OneNote',\n",
       " 'Nioh',\n",
       " 'bigseo',\n",
       " 'polyamory',\n",
       " 'Cuckold',\n",
       " 'spikes',\n",
       " 'baldursgate',\n",
       " 'drawing',\n",
       " 'unRAID',\n",
       " 'FinancialCareers',\n",
       " 'schizophrenia',\n",
       " 'lebanon',\n",
       " 'Cisco',\n",
       " 'billiards',\n",
       " 'rapecounseling',\n",
       " 'eroticauthors',\n",
       " 'CrohnsDisease',\n",
       " 'Blink182',\n",
       " 'raisedbynarcissists',\n",
       " 'oculus',\n",
       " 'cocaine',\n",
       " 'crossfit',\n",
       " 'airsoft',\n",
       " 'dashpay',\n",
       " 'DebateAltRight',\n",
       " 'ibs',\n",
       " 'Porsche',\n",
       " 'chemistry',\n",
       " 'spain',\n",
       " 'Ripple',\n",
       " 'Trucks',\n",
       " 'nosurf',\n",
       " 'psychotherapy',\n",
       " '90DayFiance',\n",
       " 'BravoRealHousewives',\n",
       " 'rccars',\n",
       " 'neoliberal',\n",
       " 'The100',\n",
       " 'Gifts',\n",
       " 'Norway',\n",
       " 'battlefield_one',\n",
       " 'Sherlock',\n",
       " 'ifttt',\n",
       " 'coins',\n",
       " 'swordartonline',\n",
       " 'danganronpa',\n",
       " 'samuraijack',\n",
       " 'Invisalign',\n",
       " 'ultrawidemasterrace',\n",
       " 'rickandmorty',\n",
       " 'ACT',\n",
       " 'rollerblading',\n",
       " 'GiIvaSunner',\n",
       " 'minimalism',\n",
       " 'Nepal',\n",
       " 'ukulele',\n",
       " 'ultimate',\n",
       " 'stevenuniverse',\n",
       " 'dwarffortress',\n",
       " 'bangtan',\n",
       " 'Korean',\n",
       " 'OnePieceTC',\n",
       " 'Ayahuasca',\n",
       " 'everquest',\n",
       " 'HongKong',\n",
       " 'Shadowrun',\n",
       " 'MTVScream',\n",
       " 'asktrp',\n",
       " 'OutreachHPG',\n",
       " 'cade',\n",
       " 'amiibo',\n",
       " 'kodi',\n",
       " 'SwagBucks',\n",
       " 'TheLeftovers',\n",
       " 'whatsthatbook',\n",
       " 'Philippines',\n",
       " 'poland',\n",
       " 'FrankOcean',\n",
       " 'pharmacy',\n",
       " 'SampleSize',\n",
       " 'actuallesbians',\n",
       " 'BMW',\n",
       " 'ZeroEscape',\n",
       " 'place',\n",
       " 'Warthunder',\n",
       " 'vinyl',\n",
       " 'Dentistry',\n",
       " 'crossdressing',\n",
       " 'thebachelor',\n",
       " 'ApocalypseRising',\n",
       " 'Hyundai',\n",
       " 'LongDistance',\n",
       " 'personalfinance',\n",
       " 'litecoin',\n",
       " 'sweden',\n",
       " 'Metalcore',\n",
       " 'Scams',\n",
       " 'cardistry',\n",
       " 'futarp',\n",
       " 'homelab',\n",
       " 'KingdomDeath',\n",
       " 'minecraftsuggestions',\n",
       " 'weed',\n",
       " 'audible',\n",
       " 'uBlockOrigin',\n",
       " 'teaching',\n",
       " 'whatsthisplant',\n",
       " 'prephysicianassistant',\n",
       " 'LearnJapanese',\n",
       " 'guineapigs',\n",
       " 'WritingPrompts',\n",
       " 'mazda3',\n",
       " 'twinpeaks',\n",
       " 'BackYardChickens',\n",
       " 'thelastofus',\n",
       " 'ChineseLanguage',\n",
       " 'southpark',\n",
       " 'IdleHeroes',\n",
       " 'riddles',\n",
       " 'Beatmatch',\n",
       " 'mturk',\n",
       " 'walmart',\n",
       " 'DDLC',\n",
       " 'immigration',\n",
       " 'AirBnB',\n",
       " 'TheHandmaidsTale',\n",
       " 'lightsabers',\n",
       " 'GhostRecon',\n",
       " 'MPSelectMiniOwners',\n",
       " 'hiking',\n",
       " 'Re_Zero',\n",
       " 'Pauper',\n",
       " 'RedditLaqueristas',\n",
       " 'singing',\n",
       " 'HomeDepot',\n",
       " 'StarVStheForcesofEvil',\n",
       " 'russia',\n",
       " 'lockpicking',\n",
       " 'swift',\n",
       " 'kickstarter',\n",
       " 'deathgrips',\n",
       " 'gameofthrones',\n",
       " 'parentsofmultiples',\n",
       " 'WoT',\n",
       " 'KingkillerChronicle',\n",
       " 'adderall',\n",
       " 'workflow',\n",
       " 'SCCM',\n",
       " 'DanLeBatardShow',\n",
       " 'Staples',\n",
       " 'CompetitiveForHonor',\n",
       " 'golang',\n",
       " 'dogecoin',\n",
       " 'pihole',\n",
       " 'russian',\n",
       " 'nihilism',\n",
       " 'FinalFantasyTCG',\n",
       " 'barstoolsports',\n",
       " 'The_Division',\n",
       " 'massage',\n",
       " 'clothdiaps',\n",
       " 'bleach',\n",
       " 'TheDarkTower',\n",
       " 'kindle',\n",
       " 'ageofsigmar',\n",
       " 'brockhampton',\n",
       " 'salesforce',\n",
       " 'opiates',\n",
       " 'amiugly',\n",
       " 'Petscop',\n",
       " 'Jazz',\n",
       " 'rugbyunion',\n",
       " 'HIMYM',\n",
       " 'dropship',\n",
       " 'benzodiazepines',\n",
       " 'Adoption',\n",
       " 'swoleacceptance',\n",
       " 'hometheater',\n",
       " 'linuxquestions',\n",
       " 'roadtrip',\n",
       " 'GilmoreGirls',\n",
       " 'Netrunner',\n",
       " 'TheLastAirbender',\n",
       " 'AskEconomics',\n",
       " 'Vermintide',\n",
       " 'running',\n",
       " 'BeautyBoxes',\n",
       " 'judo',\n",
       " 'phenibut',\n",
       " 'firefox',\n",
       " 'amazonecho',\n",
       " 'Gunpla',\n",
       " 'valkyrie_en',\n",
       " 'javahelp',\n",
       " 'bulletjournal',\n",
       " 'infertility',\n",
       " 'WormFanfic',\n",
       " 'juul',\n",
       " 'Darts',\n",
       " 'ASUS',\n",
       " 'namenerds',\n",
       " 'robotics',\n",
       " 'acting',\n",
       " 'Gloomhaven',\n",
       " 'modelmakers',\n",
       " 'CoDCompetitive',\n",
       " 'vainglorygame',\n",
       " 'TheXanaxCartel',\n",
       " 'SleepApnea',\n",
       " 'Equestrian',\n",
       " 'Steroidsourcetalk',\n",
       " 'Supernatural',\n",
       " 'arcticmonkeys',\n",
       " 'web_design',\n",
       " 'Egypt',\n",
       " 'radarr',\n",
       " 'Lisk',\n",
       " 'splatoon',\n",
       " 'privacy',\n",
       " 'optometry',\n",
       " 'warriors',\n",
       " 'overlord',\n",
       " 'short',\n",
       " 'ehlersdanlos',\n",
       " 'Metallica',\n",
       " 'LucidDreaming',\n",
       " 'gopro',\n",
       " 'GenderCritical',\n",
       " 'fitbit',\n",
       " 'chess',\n",
       " 'learndota2',\n",
       " 'interviews',\n",
       " 'raspberry_pi',\n",
       " 'ZeroWaste',\n",
       " 'dotnet',\n",
       " 'MultipleSclerosis',\n",
       " 'Jokes',\n",
       " 'TransDIY',\n",
       " 'Rainmeter',\n",
       " 'cardfightvanguard',\n",
       " 'bindingofisaac',\n",
       " 'rollercoasters',\n",
       " 'KDRAMA',\n",
       " 'linguistics',\n",
       " 'homegym',\n",
       " 'sousvide',\n",
       " 'declutter',\n",
       " 'Bowling',\n",
       " 'fountainpens',\n",
       " 'Psychic',\n",
       " 'JETProgramme',\n",
       " 'Celiac',\n",
       " 'preppers',\n",
       " 'FidgetSpinners',\n",
       " 'weedstocks',\n",
       " 'leopardgeckos',\n",
       " 'AskVet',\n",
       " 'ProtectAndServe',\n",
       " 'Turkey',\n",
       " 'DID',\n",
       " 'Endo',\n",
       " 'yorku',\n",
       " 'Anki',\n",
       " 'Genealogy',\n",
       " 'MSAccess',\n",
       " 'saab',\n",
       " 'EDM',\n",
       " 'AutoDetailing',\n",
       " 'Tronix',\n",
       " 'learnmachinelearning',\n",
       " 'emetophobia',\n",
       " 'Hypothyroidism',\n",
       " 'TaylorSwift',\n",
       " 'lightingdesign',\n",
       " 'SQL',\n",
       " 'selfhosted',\n",
       " 'physicaltherapy',\n",
       " 'DarlingInTheFranxx',\n",
       " 'pesmobile',\n",
       " 'slowcooking',\n",
       " 'poker',\n",
       " 'deaf',\n",
       " 'bloodbowl',\n",
       " 'bash',\n",
       " 'mylittlepony',\n",
       " 'Terraria',\n",
       " 'Kappa',\n",
       " 'bjj',\n",
       " 'CampHalfBloodRP',\n",
       " 'ableton',\n",
       " 'ferrets',\n",
       " 'dbz',\n",
       " 'breastfeeding',\n",
       " 'lucifer',\n",
       " 'surfing',\n",
       " 'tarantulas',\n",
       " 'AmericanHorrorStory',\n",
       " 'incest',\n",
       " 'StrangerThings',\n",
       " 'fragrance',\n",
       " 'violinist',\n",
       " 'chastity',\n",
       " 'bootroom',\n",
       " 'findareddit',\n",
       " 'actuary',\n",
       " 'LoveLive',\n",
       " 'statistics',\n",
       " 'suggestmeabook',\n",
       " 'socialism',\n",
       " 'tezos',\n",
       " '4Runner',\n",
       " 'tinnitus',\n",
       " 'mountandblade',\n",
       " 'electricians',\n",
       " 'unitedkingdom',\n",
       " 'arrow',\n",
       " 'latin',\n",
       " 'fivenightsatfreddys',\n",
       " 'Journalism',\n",
       " 'translator',\n",
       " 'vergecurrency',\n",
       " 'gradadmissions',\n",
       " 'IKEA',\n",
       " 'pakistan',\n",
       " 'binance',\n",
       " 'OCD',\n",
       " 'childfree',\n",
       " 'Cloververse',\n",
       " 'legaladviceofftopic',\n",
       " 'bipolar',\n",
       " 'BokuNoHeroAcademia',\n",
       " 'freenas',\n",
       " 'vegetarian',\n",
       " 'peacecorps',\n",
       " 'Sleepparalysis',\n",
       " 'Truckers',\n",
       " 'Machinists',\n",
       " 'deathnote',\n",
       " 'neopets',\n",
       " 'WWE',\n",
       " 'bigdickproblems',\n",
       " 'datascience',\n",
       " 'WouldYouRather',\n",
       " 'eos',\n",
       " 'Bass',\n",
       " 'tennis',\n",
       " 'DimensionalJumping',\n",
       " 'OOTP',\n",
       " 'telescopes',\n",
       " 'paypal',\n",
       " 'doctorwho',\n",
       " 'Bedbugs',\n",
       " 'HVAC',\n",
       " 'survivinginfidelity',\n",
       " 'bettafish',\n",
       " 'MarioMaker',\n",
       " 'MechanicalKeyboards',\n",
       " 'stopsmoking',\n",
       " 'newzealand',\n",
       " 'wildhearthstone',\n",
       " 'readyplayerone',\n",
       " 'beatles',\n",
       " '13ReasonsWhy',\n",
       " 'appletv',\n",
       " 'StardustCrusaders',\n",
       " 'ADHD',\n",
       " 'KendrickLamar',\n",
       " 'Kanye',\n",
       " 'radiohead',\n",
       " 'spotify',\n",
       " 'Nerf',\n",
       " 'blender',\n",
       " 'pebble',\n",
       " 'Kings_Raid',\n",
       " 'TREZOR',\n",
       " 'EARONS',\n",
       " 'cocktails',\n",
       " 'pkmntcg',\n",
       " 'twentyonepilots',\n",
       " 'rstats',\n",
       " 'korea',\n",
       " 'hapas',\n",
       " 'ftm',\n",
       " 'SCREENPRINTING',\n",
       " 'reddCoin',\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = labs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>Remember your command line switches... Hi ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>So what was Matt \"addicted\" to? Did he ever sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>No Club Colors Funny story. I went to college ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>Not door bell, but floodlight mount height. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...   \n",
       "1  Did he ever say what his addiction was or is h...   \n",
       "2  Funny story. I went to college in Las Vegas. T...   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   \n",
       "4  Prime95 (regardless of version) and OCCT both,...   \n",
       "\n",
       "                                            combined  \n",
       "0  Remember your command line switches... Hi ther...  \n",
       "1  So what was Matt \"addicted\" to? Did he ever sa...  \n",
       "2  No Club Colors Funny story. I went to college ...  \n",
       "3  Not door bell, but floodlight mount height. I ...  \n",
       "4  Worried about my 8700k small fft/data stress r...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['combined']=df['title'].str.cat(df['selftext'], sep=' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import TextField, MetadataField, ArrayField, LabelField\n",
    "\n",
    "class JigsawDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[Token], id: str=None,\n",
    "                         label: str=None) -> Instance:\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "        \n",
    "        id_field = MetadataField(id)\n",
    "        fields['id'] = id_field\n",
    "        \n",
    "        if label is not None:\n",
    "            fields['label'] = LabelField(label, label_namespace=\"subreddit\")\n",
    "        \n",
    "\n",
    "        return Instance(fields)\n",
    "# changed to pass df instead of filename in order to use combined title +selfpost    \n",
    "    @overrides\n",
    "    def _read(self, df) -> Iterator[Instance]:\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                [Token(x) for x in self.tokenizer(row[\"combined\"])],\n",
    "                row[\"id\"], row[\"subreddit\"],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare token handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the spacy tokenizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "\n",
    "# the token indexer is responsible for mapping tokens to integers\n",
    "token_indexer = ELMoTokenCharactersIndexer()\n",
    "\n",
    "def tokenizer(x: str):\n",
    "    return [w.text for w in\n",
    "            SpacyWordSplitter(language='en_core_web_sm', \n",
    "                              pos_tags=False).split_words(x)[:config.max_seq_len]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = JigsawDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "157it [00:00, 1568.85it/s]\u001b[A\n",
      "287it [00:00, 1475.27it/s]\u001b[A\n",
      "391it [00:00, 916.06it/s] \u001b[A\n",
      "465it [00:00, 852.49it/s]\u001b[A\n",
      "533it [00:00, 775.34it/s]\u001b[A\n",
      "600it [00:00, 723.99it/s]\u001b[A\n",
      "674it [00:00, 727.66it/s]\u001b[A\n",
      "745it [00:00, 715.82it/s]\u001b[A\n",
      "814it [00:01, 669.57it/s]\u001b[A\n",
      "880it [00:01, 661.27it/s]\u001b[A\n",
      "956it [00:01, 687.71it/s]\u001b[A\n",
      "1000it [00:01, 757.72it/s]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "67it [00:00, 663.13it/s]\u001b[A\n",
      "131it [00:00, 650.34it/s]\u001b[A\n",
      "207it [00:00, 674.53it/s]\u001b[A\n",
      "277it [00:00, 680.17it/s]\u001b[A\n",
      "338it [00:00, 648.33it/s]\u001b[A\n",
      "400it [00:00, 638.63it/s]\u001b[A\n",
      "477it [00:00, 672.43it/s]\u001b[A\n",
      "543it [00:00, 667.68it/s]\u001b[A\n",
      "607it [00:01, 470.21it/s]\u001b[A\n",
      "681it [00:01, 523.61it/s]\u001b[A\n",
      "746it [00:01, 555.83it/s]\u001b[A\n",
      "810it [00:01, 576.28it/s]\u001b[A\n",
      "880it [00:01, 607.49it/s]\u001b[A\n",
      "944it [00:01, 612.74it/s]\u001b[A\n",
      "1000it [00:01, 611.71it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "#split 80% train 20% test\n",
    "train_ds = reader.read(df[:810399])\n",
    "test_ds = reader.read(df[810399:]) \n",
    "val_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<allennlp.data.instance.Instance at 0x7f2679259c18>,\n",
       " <allennlp.data.instance.Instance at 0x7f267936e080>,\n",
       " <allennlp.data.instance.Instance at 0x7f2679390a90>,\n",
       " <allennlp.data.instance.Instance at 0x7f267937ccf8>,\n",
       " <allennlp.data.instance.Instance at 0x7f26791c19b0>,\n",
       " <allennlp.data.instance.Instance at 0x7f26791bcb38>,\n",
       " <allennlp.data.instance.Instance at 0x7f267921b320>,\n",
       " <allennlp.data.instance.Instance at 0x7f267917f358>,\n",
       " <allennlp.data.instance.Instance at 0x7f2679193358>,\n",
       " <allennlp.data.instance.Instance at 0x7f26791a7ac8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [Remember,\n",
       "  your,\n",
       "  command,\n",
       "  line,\n",
       "  switches,\n",
       "  ...,\n",
       "  Hi,\n",
       "  there,\n",
       "  ,,\n",
       "  <,\n",
       "  lb,\n",
       "  >,\n",
       "  The,\n",
       "  usual,\n",
       "  .,\n",
       "  Long,\n",
       "  time,\n",
       "  lerker,\n",
       "  ,,\n",
       "  first,\n",
       "  time,\n",
       "  poster,\n",
       "  ,,\n",
       "  be,\n",
       "  kind,\n",
       "  etc,\n",
       "  .,\n",
       "  Sorry,\n",
       "  if,\n",
       "  this,\n",
       "  is,\n",
       "  n't,\n",
       "  the,\n",
       "  right,\n",
       "  place,\n",
       "  ...,\n",
       "  <lb><lb,\n",
       "  >,\n",
       "  Alright,\n",
       "  .,\n",
       "  Here,\n",
       "  's,\n",
       "  the,\n",
       "  story,\n",
       "  .,\n",
       "  I,\n",
       "  'm,\n",
       "  an,\n",
       "  independent,\n",
       "  developer,\n",
       "  who,\n",
       "  produces,\n",
       "  my,\n",
       "  own,\n",
       "  software,\n",
       "  .,\n",
       "  We,\n",
       "  're,\n",
       "  going,\n",
       "  to,\n",
       "  call,\n",
       "  me,\n",
       "  well,\n",
       "  ,,\n",
       "  $,\n",
       "  me.<lb><lb,\n",
       "  >,\n",
       "  I,\n",
       "  work,\n",
       "  with,\n",
       "  $,\n",
       "  dev,\n",
       "  who,\n",
       "  helps,\n",
       "  to,\n",
       "  produce,\n",
       "  software,\n",
       "  with,\n",
       "  me,\n",
       "  .,\n",
       "  We,\n",
       "  use,\n",
       "  $,\n",
       "  PopularVersionControl.<lb><lb,\n",
       "  >,\n",
       "  We're,\n",
       "  trying,\n",
       "  to,\n",
       "  remove,\n",
       "  a,\n",
       "  branch,\n",
       "  that,\n",
       "  was,\n",
       "  created,\n",
       "  by,\n",
       "  mistake,\n",
       "  .,\n",
       "  The,\n",
       "  branch,\n",
       "  is],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x7f266d01dc18>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None,\n",
       " '_token_index_to_indexer_name': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[0].fields[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'talesfromtechsupport',\n",
       " '_label_namespace': 'subreddit',\n",
       " '_label_id': None,\n",
       " '_skip_indexing': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[0].fields[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to build the vocab: all that is handled by the token indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterator is responsible for batching the data and preparing it for input into the model. We'll use the BucketIterator that batches text sequences of smilar lengths together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=config.batch_size, \n",
    "                          sorting_keys=[(\"tokens\", \"num_tokens\")],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell the iterator how to numericalize the text data. We do this by passing the vocabulary to the iterator. This step is easy to forget so be careful! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(iterator(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  73, 102,  ..., 261, 261, 261],\n",
       "         [259,  45, 260,  ..., 261, 261, 261],\n",
       "         [259,  68,  98,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 104,  98,  ..., 261, 261, 261],\n",
       "         [259,  45, 260,  ..., 261, 261, 261],\n",
       "         [259, 111, 112,  ..., 261, 261, 261]],\n",
       "\n",
       "        [[259,  66, 111,  ..., 261, 261, 261],\n",
       "         [259, 102, 121,  ..., 261, 261, 261],\n",
       "         [259,  46, 260,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 118, 113,  ..., 261, 261, 261],\n",
       "         [259, 103, 112,  ..., 261, 261, 261],\n",
       "         [259,  77, 102,  ..., 261, 261, 261]],\n",
       "\n",
       "        [[259,  66, 101,  ..., 261, 261, 261],\n",
       "         [259, 103, 112,  ..., 261, 261, 261],\n",
       "         [259, 100, 112,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259,  98, 100,  ..., 261, 261, 261],\n",
       "         [259, 117, 112,  ..., 261, 261, 261],\n",
       "         [259,  98, 260,  ..., 261, 261, 261]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[259,  88, 105,  ..., 261, 261, 261],\n",
       "         [259,  98, 115,  ..., 261, 261, 261],\n",
       "         [259, 116, 112,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 121,  51,  ..., 261, 261, 261],\n",
       "         [259,  42, 260,  ..., 261, 261, 261],\n",
       "         [259,  47, 260,  ..., 261, 261, 261]],\n",
       "\n",
       "        [[259,  88, 105,  ..., 261, 261, 261],\n",
       "         [259,  98, 115,  ..., 261, 261, 261],\n",
       "         [259, 102, 121,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 113, 115,  ..., 261, 261, 261],\n",
       "         [259, 117, 105,  ..., 261, 261, 261],\n",
       "         [259,  98, 109,  ..., 261, 261, 261]],\n",
       "\n",
       "        [[259,  84, 112,  ..., 261, 261, 261],\n",
       "         [259, 120, 105,  ..., 261, 261, 261],\n",
       "         [259, 100,  98,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 100, 50])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "\n",
    "class BaselineModel(Model):\n",
    "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 out_sz: int=len(label_cols)):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)        \n",
    "        #self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
    "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        state = self.encoder(embeddings, mask)\n",
    "        class_logits = self.projection(state)\n",
    "        \n",
    "        output = {\"class_logits\": class_logits}\n",
    "        output[\"loss\"] = self.loss(class_logits, label)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "\n",
    "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "\n",
    "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dimension of the ELMo embedding will be 2 x [size of LSTM hidden states]\n",
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, bidirectional=True, batch_first=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how simple and modular the code for initializing the model is. All the complexity is delegated to each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(\n",
    "    word_embeddings, \n",
    "    encoder, \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: model.cuda()\n",
    "else: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.get_output_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch[\"tokens\"]\n",
    "labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = get_text_field_mask(tokens)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0980,  0.0321,  0.2379,  ...,  0.1722, -0.2032,  0.0974],\n",
       "        [-0.1167, -0.0541, -0.0688,  ...,  0.1196, -0.0654, -0.0840],\n",
       "        [-0.0474,  0.0684, -0.1666,  ...,  0.0241,  0.0820,  0.2559],\n",
       "        ...,\n",
       "        [-0.0172, -0.0043, -0.0644,  ...,  0.1197, -0.1370,  0.1961],\n",
       "        [ 0.1296,  0.0076, -0.0863,  ...,  0.1371, -0.1519, -0.0759],\n",
       "        [-0.0839, -0.0278, -0.0297,  ...,  0.2144, -0.3449,  0.0702]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.word_embeddings(tokens)\n",
    "state = model.encoder(embeddings, mask)\n",
    "class_logits = model.projection(state)\n",
    "class_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_logits': tensor([[ 0.0225,  0.0352,  0.1239,  ...,  0.0717, -0.1963,  0.1122],\n",
       "         [-0.1217, -0.0098, -0.0310,  ..., -0.0282, -0.1682,  0.1307],\n",
       "         [-0.0331,  0.0834, -0.1441,  ...,  0.0225, -0.2000, -0.0023],\n",
       "         ...,\n",
       "         [ 0.0147, -0.1620, -0.1021,  ..., -0.0043, -0.0536,  0.1194],\n",
       "         [ 0.0688,  0.0390, -0.0924,  ...,  0.1304, -0.2704,  0.0936],\n",
       "         [-0.0279, -0.1960, -0.1062,  ...,  0.3022, -0.1587,  0.1246]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " 'loss': tensor(6.9538, device='cuda:0', grad_fn=<NllLossBackward>)}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(**batch)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9708, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 8.1649e-05, -4.0192e-06, -1.7894e-04,  ...,  3.3296e-04,\n",
       "          -4.5080e-04, -1.3943e-04],\n",
       "         [-3.7892e-04, -2.8551e-04,  1.1013e-04,  ...,  4.9197e-04,\n",
       "           3.4767e-04,  2.0401e-04],\n",
       "         [-1.0234e-03, -3.2159e-04, -2.1497e-04,  ..., -6.4096e-04,\n",
       "          -9.6384e-05,  3.3268e-04],\n",
       "         ...,\n",
       "         [ 2.2296e-04,  2.6854e-04,  2.5267e-05,  ..., -5.8279e-04,\n",
       "          -4.8647e-04, -8.6643e-05],\n",
       "         [-1.6347e-05, -6.5584e-05,  7.2844e-05,  ..., -8.6177e-05,\n",
       "          -6.1994e-05, -6.5548e-05],\n",
       "         [ 2.2110e-04,  4.4802e-04, -1.8429e-05,  ...,  6.7507e-05,\n",
       "          -2.1316e-04, -7.5948e-05]], device='cuda:0'),\n",
       " tensor([[-4.0692e-05, -1.6632e-04,  2.8889e-04,  ...,  1.0030e-04,\n",
       "          -2.5475e-04,  4.2535e-06],\n",
       "         [ 3.0712e-05,  8.6505e-05, -1.3134e-04,  ..., -1.7953e-04,\n",
       "           1.3291e-04,  1.2732e-04],\n",
       "         [-2.1602e-04, -8.0404e-05,  4.1226e-05,  ...,  1.3235e-04,\n",
       "          -1.2508e-04, -3.1627e-04],\n",
       "         ...,\n",
       "         [ 3.8814e-05,  4.2684e-05, -1.6989e-04,  ..., -6.0675e-04,\n",
       "          -2.8240e-05,  1.6619e-04],\n",
       "         [-5.0640e-05, -4.6745e-05,  1.1135e-04,  ...,  1.0005e-05,\n",
       "          -1.6438e-04, -5.7799e-05],\n",
       "         [-7.6589e-05,  3.5679e-05,  7.9070e-06,  ...,  4.7372e-05,\n",
       "           5.2428e-05,  4.8703e-04]], device='cuda:0'),\n",
       " tensor([ 1.5052e-03, -1.4738e-03,  2.5168e-03,  8.0283e-04,  1.4014e-05,\n",
       "          1.3426e-03, -1.1469e-04,  3.6813e-04,  1.2464e-03, -7.5068e-04,\n",
       "          3.3548e-03,  1.3903e-05,  1.1995e-04, -4.1314e-04, -7.6937e-04,\n",
       "         -5.0712e-04,  4.6879e-05,  1.3010e-03,  2.4607e-04,  1.7247e-03,\n",
       "         -1.7255e-04, -1.9979e-03,  5.8443e-04, -2.3207e-04,  9.4535e-04,\n",
       "          1.3823e-03, -1.6895e-05, -6.8918e-05, -8.2523e-05, -2.6234e-03,\n",
       "          1.2273e-03,  8.1604e-04, -7.9052e-04,  2.7932e-04,  5.1401e-04,\n",
       "         -9.6298e-04, -3.0923e-03,  5.2112e-04, -1.2325e-03, -1.1953e-04,\n",
       "         -5.5124e-04,  1.7852e-03, -2.5361e-04, -5.5145e-04, -3.0076e-04,\n",
       "          1.6643e-04, -2.4706e-03,  7.9084e-04,  1.1320e-03, -4.3993e-04,\n",
       "          1.8675e-03,  1.2445e-03, -1.4963e-05, -7.8505e-05,  3.5436e-03,\n",
       "         -1.9042e-03,  9.9843e-05,  3.5137e-04, -2.6900e-04, -2.9354e-05,\n",
       "          5.0566e-05, -7.3482e-04,  4.3777e-04, -4.9077e-04,  2.0871e-03,\n",
       "         -1.6737e-03,  2.8994e-03,  6.6201e-04, -1.8487e-04, -6.1248e-04,\n",
       "         -1.4462e-04,  3.3997e-04,  2.0348e-03,  2.7290e-05,  3.1199e-03,\n",
       "          3.4326e-04,  9.2264e-05, -1.8982e-04, -4.5073e-04, -3.6778e-04,\n",
       "         -1.7137e-05,  2.2470e-03,  1.6036e-04,  2.3633e-03, -1.2301e-04,\n",
       "         -2.0364e-03,  1.4845e-04, -1.7894e-04,  6.9436e-05,  2.0268e-03,\n",
       "         -1.7101e-04, -1.5598e-04, -1.1736e-03, -1.1676e-03,  8.0179e-04,\n",
       "          1.7428e-03, -8.1011e-04,  3.3730e-04,  6.5001e-04, -3.9905e-04,\n",
       "         -2.7646e-03,  2.5579e-04, -1.6211e-03, -2.2765e-04, -6.3785e-04,\n",
       "          1.1433e-03, -8.1193e-05,  1.7894e-04, -3.4352e-04,  1.0689e-04,\n",
       "         -2.5924e-03,  9.5653e-04,  2.6009e-03, -6.9540e-04,  1.5501e-03,\n",
       "          1.4703e-04,  9.4914e-04,  2.8127e-04,  2.5821e-03, -9.8275e-04,\n",
       "          6.6053e-04,  6.7453e-04, -1.7709e-04,  1.5282e-04, -1.4890e-05,\n",
       "         -1.9769e-03,  6.0683e-04, -1.3970e-03, -1.8841e-02,  1.3111e-02,\n",
       "          2.0947e-02,  1.6745e-02,  1.1719e-02,  1.5385e-02, -3.1690e-03,\n",
       "          1.0855e-02,  2.1961e-02, -3.3695e-03, -1.9228e-02,  1.1849e-02,\n",
       "          3.7594e-04,  1.2366e-02, -1.0430e-02, -7.6205e-03,  1.8087e-03,\n",
       "          1.9873e-02, -3.6309e-03, -2.3011e-02,  1.0361e-02,  2.6013e-02,\n",
       "          6.8155e-03,  1.4011e-03,  2.4699e-02,  1.7715e-02, -1.1713e-03,\n",
       "          1.9400e-03, -1.7684e-02,  2.1326e-02, -4.3150e-03, -1.1580e-02,\n",
       "         -3.4752e-02,  2.2096e-02, -6.4661e-03, -1.2038e-02,  1.6229e-02,\n",
       "         -5.6288e-03, -8.3920e-03,  3.0943e-03,  6.8339e-03,  8.9479e-03,\n",
       "         -1.3504e-02,  1.3158e-02,  5.3769e-03, -6.3030e-03, -2.2780e-02,\n",
       "         -3.2304e-03, -1.9451e-02,  8.9047e-03, -1.5015e-02, -2.0062e-02,\n",
       "          1.9823e-02, -1.4200e-02,  2.0188e-02,  2.5773e-02, -5.3018e-03,\n",
       "         -2.1711e-02,  2.0261e-03,  4.0521e-03,  1.8928e-03, -2.3208e-02,\n",
       "         -2.6285e-03,  1.1351e-02,  2.1407e-03, -2.4136e-03,  2.2873e-03,\n",
       "          1.0143e-03, -5.5795e-05,  9.5171e-04, -7.8915e-05,  2.0903e-04,\n",
       "          1.5569e-03, -9.6730e-04,  3.6458e-03,  1.9441e-04,  3.2545e-04,\n",
       "         -4.1033e-04, -6.2002e-04, -4.7666e-04,  7.2794e-05,  1.1560e-03,\n",
       "          3.6407e-04,  1.8774e-03, -4.4573e-04, -2.4522e-03,  4.4017e-04,\n",
       "         -2.7788e-04,  7.4367e-04,  2.0068e-03, -7.0206e-05,  1.3851e-05,\n",
       "         -7.9565e-04, -3.2856e-03,  8.1815e-04,  1.1635e-03, -2.5336e-04,\n",
       "          8.0962e-04,  7.8082e-04, -9.9159e-04, -4.7478e-03,  6.8398e-04,\n",
       "         -2.1323e-03, -2.9154e-04, -8.5411e-04,  2.3563e-03, -4.8339e-04,\n",
       "         -5.7138e-04, -3.1340e-04,  4.3412e-04, -4.1807e-03,  1.0414e-03,\n",
       "          2.4847e-03, -3.8293e-04,  1.9288e-03,  7.1076e-04,  3.6412e-05,\n",
       "         -2.1227e-04,  3.0828e-03, -3.0136e-03,  1.9214e-04,  3.0511e-04,\n",
       "         -3.6162e-04,  2.1885e-05,  7.8015e-05, -8.4565e-04,  6.2741e-04,\n",
       "         -3.7441e-04], device='cuda:0'),\n",
       " tensor([ 1.5052e-03, -1.4738e-03,  2.5168e-03,  8.0283e-04,  1.4014e-05,\n",
       "          1.3426e-03, -1.1469e-04,  3.6813e-04,  1.2464e-03, -7.5068e-04,\n",
       "          3.3548e-03,  1.3903e-05,  1.1995e-04, -4.1314e-04, -7.6937e-04,\n",
       "         -5.0712e-04,  4.6879e-05,  1.3010e-03,  2.4607e-04,  1.7247e-03,\n",
       "         -1.7255e-04, -1.9979e-03,  5.8443e-04, -2.3207e-04,  9.4535e-04,\n",
       "          1.3823e-03, -1.6895e-05, -6.8918e-05, -8.2523e-05, -2.6234e-03,\n",
       "          1.2273e-03,  8.1604e-04, -7.9052e-04,  2.7932e-04,  5.1401e-04,\n",
       "         -9.6298e-04, -3.0923e-03,  5.2112e-04, -1.2325e-03, -1.1953e-04,\n",
       "         -5.5124e-04,  1.7852e-03, -2.5361e-04, -5.5145e-04, -3.0076e-04,\n",
       "          1.6643e-04, -2.4706e-03,  7.9084e-04,  1.1320e-03, -4.3993e-04,\n",
       "          1.8675e-03,  1.2445e-03, -1.4963e-05, -7.8505e-05,  3.5436e-03,\n",
       "         -1.9042e-03,  9.9843e-05,  3.5137e-04, -2.6900e-04, -2.9354e-05,\n",
       "          5.0566e-05, -7.3482e-04,  4.3777e-04, -4.9077e-04,  2.0871e-03,\n",
       "         -1.6737e-03,  2.8994e-03,  6.6201e-04, -1.8487e-04, -6.1248e-04,\n",
       "         -1.4462e-04,  3.3997e-04,  2.0348e-03,  2.7290e-05,  3.1199e-03,\n",
       "          3.4326e-04,  9.2264e-05, -1.8982e-04, -4.5073e-04, -3.6778e-04,\n",
       "         -1.7137e-05,  2.2470e-03,  1.6036e-04,  2.3633e-03, -1.2301e-04,\n",
       "         -2.0364e-03,  1.4845e-04, -1.7894e-04,  6.9436e-05,  2.0268e-03,\n",
       "         -1.7101e-04, -1.5598e-04, -1.1736e-03, -1.1676e-03,  8.0179e-04,\n",
       "          1.7428e-03, -8.1011e-04,  3.3730e-04,  6.5001e-04, -3.9905e-04,\n",
       "         -2.7646e-03,  2.5579e-04, -1.6211e-03, -2.2765e-04, -6.3785e-04,\n",
       "          1.1433e-03, -8.1193e-05,  1.7894e-04, -3.4352e-04,  1.0689e-04,\n",
       "         -2.5924e-03,  9.5653e-04,  2.6009e-03, -6.9540e-04,  1.5501e-03,\n",
       "          1.4703e-04,  9.4914e-04,  2.8127e-04,  2.5821e-03, -9.8275e-04,\n",
       "          6.6053e-04,  6.7453e-04, -1.7709e-04,  1.5282e-04, -1.4890e-05,\n",
       "         -1.9769e-03,  6.0683e-04, -1.3970e-03, -1.8841e-02,  1.3111e-02,\n",
       "          2.0947e-02,  1.6745e-02,  1.1719e-02,  1.5385e-02, -3.1690e-03,\n",
       "          1.0855e-02,  2.1961e-02, -3.3695e-03, -1.9228e-02,  1.1849e-02,\n",
       "          3.7594e-04,  1.2366e-02, -1.0430e-02, -7.6205e-03,  1.8087e-03,\n",
       "          1.9873e-02, -3.6309e-03, -2.3011e-02,  1.0361e-02,  2.6013e-02,\n",
       "          6.8155e-03,  1.4011e-03,  2.4699e-02,  1.7715e-02, -1.1713e-03,\n",
       "          1.9400e-03, -1.7684e-02,  2.1326e-02, -4.3150e-03, -1.1580e-02,\n",
       "         -3.4752e-02,  2.2096e-02, -6.4661e-03, -1.2038e-02,  1.6229e-02,\n",
       "         -5.6288e-03, -8.3920e-03,  3.0943e-03,  6.8339e-03,  8.9479e-03,\n",
       "         -1.3504e-02,  1.3158e-02,  5.3769e-03, -6.3030e-03, -2.2780e-02,\n",
       "         -3.2304e-03, -1.9451e-02,  8.9047e-03, -1.5015e-02, -2.0062e-02,\n",
       "          1.9823e-02, -1.4200e-02,  2.0188e-02,  2.5773e-02, -5.3018e-03,\n",
       "         -2.1711e-02,  2.0261e-03,  4.0521e-03,  1.8928e-03, -2.3208e-02,\n",
       "         -2.6285e-03,  1.1351e-02,  2.1407e-03, -2.4136e-03,  2.2873e-03,\n",
       "          1.0143e-03, -5.5795e-05,  9.5171e-04, -7.8915e-05,  2.0903e-04,\n",
       "          1.5569e-03, -9.6730e-04,  3.6458e-03,  1.9441e-04,  3.2545e-04,\n",
       "         -4.1033e-04, -6.2002e-04, -4.7666e-04,  7.2794e-05,  1.1560e-03,\n",
       "          3.6407e-04,  1.8774e-03, -4.4573e-04, -2.4522e-03,  4.4017e-04,\n",
       "         -2.7788e-04,  7.4367e-04,  2.0068e-03, -7.0206e-05,  1.3851e-05,\n",
       "         -7.9565e-04, -3.2856e-03,  8.1815e-04,  1.1635e-03, -2.5336e-04,\n",
       "          8.0962e-04,  7.8082e-04, -9.9159e-04, -4.7478e-03,  6.8398e-04,\n",
       "         -2.1323e-03, -2.9154e-04, -8.5411e-04,  2.3563e-03, -4.8339e-04,\n",
       "         -5.7138e-04, -3.1340e-04,  4.3412e-04, -4.1807e-03,  1.0414e-03,\n",
       "          2.4847e-03, -3.8293e-04,  1.9288e-03,  7.1076e-04,  3.6412e-05,\n",
       "         -2.1227e-04,  3.0828e-03, -3.0136e-03,  1.9214e-04,  3.0511e-04,\n",
       "         -3.6162e-04,  2.1885e-05,  7.8015e-05, -8.4565e-04,  6.2741e-04,\n",
       "         -3.7441e-04], device='cuda:0'),\n",
       " tensor([[-2.7501e-05,  7.9488e-06, -2.4356e-04,  ...,  3.6308e-05,\n",
       "           6.4798e-05,  2.3105e-04],\n",
       "         [-1.4874e-04,  3.6237e-05, -1.2521e-04,  ..., -2.4367e-04,\n",
       "          -1.7480e-04, -3.7642e-04],\n",
       "         [-1.6390e-04, -2.1362e-04, -9.0970e-06,  ..., -3.3629e-05,\n",
       "          -6.4875e-05, -1.8097e-05],\n",
       "         ...,\n",
       "         [ 6.4561e-05, -5.8880e-05, -1.5662e-04,  ..., -1.5605e-04,\n",
       "          -3.2822e-06,  5.4027e-05],\n",
       "         [ 1.6245e-04,  9.0878e-04,  5.6292e-04,  ..., -1.9192e-04,\n",
       "          -5.2568e-04,  4.1540e-04],\n",
       "         [-4.9976e-04, -8.5892e-04,  1.0119e-03,  ...,  1.9046e-04,\n",
       "           1.9064e-04,  5.2374e-04]], device='cuda:0'),\n",
       " tensor([[-3.7510e-07, -9.3194e-06,  1.6558e-05,  ...,  1.4436e-05,\n",
       "          -2.0462e-05,  9.9113e-06],\n",
       "         [-8.0995e-06, -2.2885e-05, -7.7714e-05,  ..., -1.7801e-05,\n",
       "           3.1268e-05, -5.9663e-05],\n",
       "         [ 4.8827e-06, -5.0300e-05, -7.5317e-05,  ..., -2.9954e-05,\n",
       "           2.9628e-05,  2.7652e-05],\n",
       "         ...,\n",
       "         [-6.0372e-06,  4.5047e-06,  3.6690e-05,  ..., -6.6452e-05,\n",
       "           6.1629e-06, -1.0346e-05],\n",
       "         [ 1.8967e-05, -6.0299e-06, -7.5138e-06,  ...,  1.1288e-04,\n",
       "          -3.3211e-04, -1.3310e-04],\n",
       "         [ 4.9107e-05, -9.7624e-06,  4.2296e-04,  ...,  3.4364e-04,\n",
       "          -6.1394e-05,  5.1675e-04]], device='cuda:0'),\n",
       " tensor([-2.5260e-04,  3.2834e-04,  3.3393e-04,  3.5344e-03, -9.0257e-05,\n",
       "          9.5633e-04,  1.2088e-03, -2.5723e-03, -2.6932e-03,  1.5417e-03,\n",
       "          6.5099e-04, -1.9939e-03,  3.6687e-03, -1.7634e-03,  1.9261e-04,\n",
       "          1.3979e-03,  2.0597e-03, -6.8782e-04,  4.4861e-04,  2.9009e-03,\n",
       "         -2.8070e-03,  1.0976e-04,  1.9350e-03,  1.2183e-03, -1.0585e-04,\n",
       "          3.3092e-04, -5.6293e-03,  4.8215e-04, -1.8273e-03,  2.8463e-04,\n",
       "         -3.3342e-04,  2.0288e-03,  1.8420e-03, -1.8088e-05,  2.3278e-04,\n",
       "         -1.0592e-03, -6.9763e-04,  9.6009e-04,  1.6628e-04,  3.7725e-03,\n",
       "          1.5679e-04, -8.1578e-04, -3.0144e-03, -6.7849e-04, -6.2637e-04,\n",
       "         -6.0087e-03, -1.0674e-04, -2.5881e-03,  1.4594e-03,  3.5599e-03,\n",
       "         -3.5373e-03, -1.2091e-03,  2.6871e-05, -1.6826e-03, -4.7063e-05,\n",
       "          2.1928e-03, -8.1278e-04, -1.7448e-04,  2.6605e-05,  1.0062e-03,\n",
       "          3.4845e-03,  2.1825e-04, -3.4480e-04, -6.1073e-05, -2.0444e-04,\n",
       "          1.6064e-04, -3.3708e-04,  6.5725e-04, -1.1209e-04,  9.8750e-04,\n",
       "          5.2351e-04, -1.3967e-03, -9.6284e-04,  1.0595e-03,  3.5225e-04,\n",
       "         -3.5202e-03,  3.4057e-03, -1.6837e-03,  2.6878e-03,  1.1504e-03,\n",
       "          8.5056e-04, -1.1569e-03,  1.4483e-03,  2.7504e-03, -1.6495e-03,\n",
       "         -2.8342e-04,  1.3096e-03,  1.8709e-03, -1.0640e-05,  1.8877e-04,\n",
       "         -3.9773e-03, -2.1072e-03, -6.5569e-04,  3.8283e-04,  6.6106e-04,\n",
       "          9.0439e-04, -3.3289e-04,  4.3676e-05, -1.6322e-04, -1.1988e-03,\n",
       "         -8.3351e-04,  5.0215e-04,  1.2949e-04,  4.7109e-03,  8.6238e-05,\n",
       "         -8.8132e-04, -2.2563e-03, -1.6432e-03, -1.9525e-03, -3.4234e-03,\n",
       "         -2.7681e-04, -1.5668e-03,  1.3240e-03,  2.4664e-03, -3.2139e-03,\n",
       "         -2.7994e-04, -2.4161e-05, -1.9487e-03, -6.6206e-05,  3.9289e-03,\n",
       "         -3.0149e-04,  1.5488e-05,  1.6246e-04, -9.7900e-04,  2.8089e-03,\n",
       "          1.6559e-04, -1.7745e-03, -1.1571e-03,  2.8228e-03, -7.8851e-03,\n",
       "          3.8855e-03,  1.1098e-02, -3.7066e-03,  7.9061e-03,  8.7892e-03,\n",
       "         -1.9451e-02, -2.9805e-02, -3.0787e-02, -1.3914e-02, -1.6243e-02,\n",
       "          1.0389e-02, -1.8101e-02, -2.5102e-02, -1.3919e-02, -2.3376e-02,\n",
       "          2.4104e-02, -2.0446e-02, -1.3293e-02, -2.0067e-02,  3.4774e-03,\n",
       "         -7.9286e-03,  2.6311e-02, -3.8921e-03, -1.7218e-03, -1.3771e-02,\n",
       "          2.6414e-02,  1.4105e-02, -1.1271e-02, -3.5541e-04,  9.5022e-03,\n",
       "         -1.7148e-02,  1.2271e-03, -5.0124e-03, -1.3993e-02,  2.6359e-02,\n",
       "         -2.3475e-03,  2.3929e-03,  1.4046e-02, -3.9771e-05, -1.1650e-02,\n",
       "          2.0169e-02,  1.3580e-02, -1.8789e-02, -1.8739e-02, -4.7559e-03,\n",
       "         -9.9647e-03,  9.2779e-03,  2.1679e-02, -2.7993e-02,  1.2571e-02,\n",
       "          1.3580e-03,  1.9065e-02, -5.4119e-03, -1.9282e-02,  7.2881e-03,\n",
       "          2.1479e-02,  7.7835e-04,  1.9629e-02, -1.8188e-02, -7.0357e-04,\n",
       "         -1.4122e-02,  2.8929e-02, -2.1276e-04,  6.8125e-04,  1.2756e-04,\n",
       "          3.5639e-03, -4.3683e-05,  1.3242e-03,  1.1155e-03, -2.9004e-03,\n",
       "         -2.2721e-03,  2.0117e-03,  6.2543e-04, -2.0577e-03,  3.7368e-03,\n",
       "         -1.9493e-03,  1.3218e-03,  2.3069e-03,  1.0716e-03, -9.3908e-04,\n",
       "         -8.7091e-05,  2.7976e-03, -1.0570e-03,  2.5525e-04,  2.1298e-03,\n",
       "          1.2864e-03, -1.7166e-06,  7.7854e-04, -7.3393e-03,  6.1070e-04,\n",
       "         -2.2016e-03,  6.5679e-04, -3.4869e-04,  3.2566e-03,  2.6964e-03,\n",
       "          7.3309e-06,  1.1873e-04, -1.4158e-03, -2.0891e-03,  1.5262e-03,\n",
       "          2.3829e-04,  4.4594e-03,  2.5321e-04, -1.1663e-03, -4.5869e-03,\n",
       "         -8.7473e-04, -1.1136e-03, -5.3899e-03,  1.4625e-04, -1.9475e-03,\n",
       "          2.3402e-03,  2.5711e-03, -4.6722e-03, -1.1711e-03,  1.0189e-04,\n",
       "         -2.4411e-03, -5.8420e-05,  3.2673e-03, -1.2904e-03, -5.3925e-04,\n",
       "          5.0294e-05,  1.3961e-03,  4.2782e-03,  3.0219e-04, -4.4333e-04,\n",
       "         -1.5595e-03], device='cuda:0'),\n",
       " tensor([-2.5260e-04,  3.2834e-04,  3.3393e-04,  3.5344e-03, -9.0257e-05,\n",
       "          9.5633e-04,  1.2088e-03, -2.5723e-03, -2.6932e-03,  1.5417e-03,\n",
       "          6.5099e-04, -1.9939e-03,  3.6687e-03, -1.7634e-03,  1.9261e-04,\n",
       "          1.3979e-03,  2.0597e-03, -6.8782e-04,  4.4861e-04,  2.9009e-03,\n",
       "         -2.8070e-03,  1.0976e-04,  1.9350e-03,  1.2183e-03, -1.0585e-04,\n",
       "          3.3092e-04, -5.6293e-03,  4.8215e-04, -1.8273e-03,  2.8463e-04,\n",
       "         -3.3342e-04,  2.0288e-03,  1.8420e-03, -1.8088e-05,  2.3278e-04,\n",
       "         -1.0592e-03, -6.9763e-04,  9.6009e-04,  1.6628e-04,  3.7725e-03,\n",
       "          1.5679e-04, -8.1578e-04, -3.0144e-03, -6.7849e-04, -6.2637e-04,\n",
       "         -6.0087e-03, -1.0674e-04, -2.5881e-03,  1.4594e-03,  3.5599e-03,\n",
       "         -3.5373e-03, -1.2091e-03,  2.6871e-05, -1.6826e-03, -4.7063e-05,\n",
       "          2.1928e-03, -8.1278e-04, -1.7448e-04,  2.6605e-05,  1.0062e-03,\n",
       "          3.4845e-03,  2.1825e-04, -3.4480e-04, -6.1073e-05, -2.0444e-04,\n",
       "          1.6064e-04, -3.3708e-04,  6.5725e-04, -1.1209e-04,  9.8750e-04,\n",
       "          5.2351e-04, -1.3967e-03, -9.6284e-04,  1.0595e-03,  3.5225e-04,\n",
       "         -3.5202e-03,  3.4057e-03, -1.6837e-03,  2.6878e-03,  1.1504e-03,\n",
       "          8.5056e-04, -1.1569e-03,  1.4483e-03,  2.7504e-03, -1.6495e-03,\n",
       "         -2.8342e-04,  1.3096e-03,  1.8709e-03, -1.0640e-05,  1.8877e-04,\n",
       "         -3.9773e-03, -2.1072e-03, -6.5569e-04,  3.8283e-04,  6.6106e-04,\n",
       "          9.0439e-04, -3.3289e-04,  4.3676e-05, -1.6322e-04, -1.1988e-03,\n",
       "         -8.3351e-04,  5.0215e-04,  1.2949e-04,  4.7109e-03,  8.6238e-05,\n",
       "         -8.8132e-04, -2.2563e-03, -1.6432e-03, -1.9525e-03, -3.4234e-03,\n",
       "         -2.7681e-04, -1.5668e-03,  1.3240e-03,  2.4664e-03, -3.2139e-03,\n",
       "         -2.7994e-04, -2.4161e-05, -1.9487e-03, -6.6206e-05,  3.9289e-03,\n",
       "         -3.0149e-04,  1.5488e-05,  1.6246e-04, -9.7900e-04,  2.8089e-03,\n",
       "          1.6559e-04, -1.7745e-03, -1.1571e-03,  2.8228e-03, -7.8851e-03,\n",
       "          3.8855e-03,  1.1098e-02, -3.7066e-03,  7.9061e-03,  8.7892e-03,\n",
       "         -1.9451e-02, -2.9805e-02, -3.0787e-02, -1.3914e-02, -1.6243e-02,\n",
       "          1.0389e-02, -1.8101e-02, -2.5102e-02, -1.3919e-02, -2.3376e-02,\n",
       "          2.4104e-02, -2.0446e-02, -1.3293e-02, -2.0067e-02,  3.4774e-03,\n",
       "         -7.9286e-03,  2.6311e-02, -3.8921e-03, -1.7218e-03, -1.3771e-02,\n",
       "          2.6414e-02,  1.4105e-02, -1.1271e-02, -3.5541e-04,  9.5022e-03,\n",
       "         -1.7148e-02,  1.2271e-03, -5.0124e-03, -1.3993e-02,  2.6359e-02,\n",
       "         -2.3475e-03,  2.3929e-03,  1.4046e-02, -3.9771e-05, -1.1650e-02,\n",
       "          2.0169e-02,  1.3580e-02, -1.8789e-02, -1.8739e-02, -4.7559e-03,\n",
       "         -9.9647e-03,  9.2779e-03,  2.1679e-02, -2.7993e-02,  1.2571e-02,\n",
       "          1.3580e-03,  1.9065e-02, -5.4119e-03, -1.9282e-02,  7.2881e-03,\n",
       "          2.1479e-02,  7.7835e-04,  1.9629e-02, -1.8188e-02, -7.0357e-04,\n",
       "         -1.4122e-02,  2.8929e-02, -2.1276e-04,  6.8125e-04,  1.2756e-04,\n",
       "          3.5639e-03, -4.3683e-05,  1.3242e-03,  1.1155e-03, -2.9004e-03,\n",
       "         -2.2721e-03,  2.0117e-03,  6.2543e-04, -2.0577e-03,  3.7368e-03,\n",
       "         -1.9493e-03,  1.3218e-03,  2.3069e-03,  1.0716e-03, -9.3908e-04,\n",
       "         -8.7091e-05,  2.7976e-03, -1.0570e-03,  2.5525e-04,  2.1298e-03,\n",
       "          1.2864e-03, -1.7166e-06,  7.7854e-04, -7.3393e-03,  6.1070e-04,\n",
       "         -2.2016e-03,  6.5679e-04, -3.4869e-04,  3.2566e-03,  2.6964e-03,\n",
       "          7.3309e-06,  1.1873e-04, -1.4158e-03, -2.0891e-03,  1.5262e-03,\n",
       "          2.3829e-04,  4.4594e-03,  2.5321e-04, -1.1663e-03, -4.5869e-03,\n",
       "         -8.7473e-04, -1.1136e-03, -5.3899e-03,  1.4625e-04, -1.9475e-03,\n",
       "          2.3402e-03,  2.5711e-03, -4.6722e-03, -1.1711e-03,  1.0189e-04,\n",
       "         -2.4411e-03, -5.8420e-05,  3.2673e-03, -1.2904e-03, -5.3925e-04,\n",
       "          5.0294e-05,  1.3961e-03,  4.2782e-03,  3.0219e-04, -4.4333e-04,\n",
       "         -1.5595e-03], device='cuda:0')]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.grad for x in list(model.encoder.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f2697701930>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    cuda_device=0 if USE_GPU else -1,\n",
    "    num_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "loss: 6.9842 ||:   5%|         | 1/21 [00:00<00:06,  3.18it/s]\u001b[A\n",
      "loss: 6.9582 ||:  10%|         | 2/21 [00:00<00:05,  3.45it/s]\u001b[A\n",
      "loss: 6.9339 ||:  14%|        | 3/21 [00:00<00:05,  3.59it/s]\u001b[A\n",
      "loss: 6.9163 ||:  19%|        | 4/21 [00:01<00:04,  3.70it/s]\u001b[A\n",
      "loss: 6.8950 ||:  24%|       | 5/21 [00:01<00:04,  3.77it/s]\u001b[A\n",
      "loss: 6.8776 ||:  29%|       | 6/21 [00:01<00:03,  4.10it/s]\u001b[A\n",
      "loss: 6.8626 ||:  33%|      | 7/21 [00:01<00:03,  4.07it/s]\u001b[A\n",
      "loss: 6.8455 ||:  38%|      | 8/21 [00:02<00:03,  4.04it/s]\u001b[A\n",
      "loss: 6.8283 ||:  43%|     | 9/21 [00:02<00:03,  3.99it/s]\u001b[A\n",
      "loss: 6.8136 ||:  48%|     | 10/21 [00:02<00:02,  3.96it/s]\u001b[A\n",
      "loss: 6.7943 ||:  52%|    | 11/21 [00:02<00:02,  4.09it/s]\u001b[A\n",
      "loss: 6.7761 ||:  57%|    | 12/21 [00:02<00:02,  4.05it/s]\u001b[A\n",
      "loss: 6.7608 ||:  62%|   | 13/21 [00:03<00:01,  4.02it/s]\u001b[A\n",
      "loss: 6.7442 ||:  67%|   | 14/21 [00:03<00:01,  3.98it/s]\u001b[A\n",
      "loss: 6.7283 ||:  71%|  | 15/21 [00:03<00:01,  3.96it/s]\u001b[A\n",
      "loss: 6.7074 ||:  76%|  | 16/21 [00:04<00:01,  3.95it/s]\u001b[A\n",
      "loss: 6.6856 ||:  81%|  | 17/21 [00:04<00:00,  4.17it/s]\u001b[A\n",
      "loss: 6.6664 ||:  86%| | 18/21 [00:04<00:00,  4.10it/s]\u001b[A\n",
      "loss: 6.6483 ||:  90%| | 19/21 [00:04<00:00,  4.05it/s]\u001b[A\n",
      "loss: 6.6282 ||:  95%|| 20/21 [00:04<00:00,  4.00it/s]\u001b[A\n",
      "loss: 6.6070 ||: 100%|| 21/21 [00:05<00:00,  3.99it/s]\u001b[A\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "loss: 6.1585 ||:   5%|         | 1/21 [00:00<00:05,  3.42it/s]\u001b[A\n",
      "loss: 6.1126 ||:  10%|         | 2/21 [00:00<00:05,  3.55it/s]\u001b[A\n",
      "loss: 6.0734 ||:  14%|        | 3/21 [00:00<00:04,  3.65it/s]\u001b[A\n",
      "loss: 6.0427 ||:  19%|        | 4/21 [00:01<00:04,  3.81it/s]\u001b[A\n",
      "loss: 6.0126 ||:  24%|       | 5/21 [00:01<00:04,  3.86it/s]\u001b[A\n",
      "loss: 5.9702 ||:  29%|       | 6/21 [00:01<00:03,  3.87it/s]\u001b[A\n",
      "loss: 5.9320 ||:  33%|      | 7/21 [00:01<00:03,  4.22it/s]\u001b[A\n",
      "loss: 5.8859 ||:  38%|      | 8/21 [00:01<00:03,  4.13it/s]\u001b[A\n",
      "loss: 5.8553 ||:  43%|     | 9/21 [00:02<00:02,  4.02it/s]\u001b[A\n",
      "loss: 5.8258 ||:  48%|     | 10/21 [00:02<00:02,  3.97it/s]\u001b[A\n",
      "loss: 5.7936 ||:  52%|    | 11/21 [00:02<00:02,  3.94it/s]\u001b[A\n",
      "loss: 5.7464 ||:  57%|    | 12/21 [00:03<00:02,  3.96it/s]\u001b[A\n",
      "loss: 5.7076 ||:  62%|   | 13/21 [00:03<00:02,  3.93it/s]\u001b[A\n",
      "loss: 5.6658 ||:  67%|   | 14/21 [00:03<00:01,  3.89it/s]\u001b[A\n",
      "loss: 5.6211 ||:  71%|  | 15/21 [00:03<00:01,  3.88it/s]\u001b[A\n",
      "loss: 5.5758 ||:  76%|  | 16/21 [00:04<00:01,  3.87it/s]\u001b[A\n",
      "loss: 5.5226 ||:  81%|  | 17/21 [00:04<00:00,  4.10it/s]\u001b[A\n",
      "loss: 5.4688 ||:  86%| | 18/21 [00:04<00:00,  4.17it/s]\u001b[A\n",
      "loss: 5.4176 ||:  90%| | 19/21 [00:04<00:00,  4.09it/s]\u001b[A\n",
      "loss: 5.3656 ||:  95%|| 20/21 [00:05<00:00,  4.01it/s]\u001b[A\n",
      "loss: 5.3119 ||: 100%|| 21/21 [00:05<00:00,  3.96it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import DataIterator\n",
    "from tqdm import tqdm\n",
    "from scipy.special import expit # the sigmoid function\n",
    "\n",
    "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model: Model, iterator: DataIterator,\n",
    "                 cuda_device: int=-1) -> None:\n",
    "        self.model = model\n",
    "        self.iterator = iterator\n",
    "        self.cuda_device = cuda_device\n",
    "        \n",
    "    def _extract_data(self, batch) -> np.ndarray:\n",
    "        out_dict = self.model(**batch)\n",
    "        return expit(tonp(out_dict[\"class_logits\"]))\n",
    "    \n",
    "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
    "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
    "        self.model.eval()\n",
    "        pred_generator_tqdm = tqdm(pred_generator,\n",
    "                                   total=self.iterator.get_num_batches(ds))\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in pred_generator_tqdm:\n",
    "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
    "                preds.append(self._extract_data(batch))\n",
    "        return np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BasicIterator\n",
    "# iterate over the dataset without changing its order\n",
    "seq_iterator = BasicIterator(batch_size=64)\n",
    "seq_iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|         | 1/16 [00:00<00:05,  2.57it/s]\u001b[A\n",
      " 12%|        | 2/16 [00:00<00:04,  2.83it/s]\u001b[A\n",
      " 19%|        | 3/16 [00:00<00:04,  3.05it/s]\u001b[A\n",
      " 25%|       | 4/16 [00:01<00:03,  3.21it/s]\u001b[A\n",
      " 31%|      | 5/16 [00:01<00:03,  3.35it/s]\u001b[A\n",
      " 38%|      | 6/16 [00:01<00:02,  3.44it/s]\u001b[A\n",
      " 44%|     | 7/16 [00:02<00:02,  3.51it/s]\u001b[A\n",
      " 50%|     | 8/16 [00:02<00:02,  3.56it/s]\u001b[A\n",
      " 56%|    | 9/16 [00:02<00:01,  3.60it/s]\u001b[A\n",
      " 62%|   | 10/16 [00:02<00:01,  3.63it/s]\u001b[A\n",
      " 69%|   | 11/16 [00:03<00:01,  3.63it/s]\u001b[A\n",
      " 75%|  | 12/16 [00:03<00:01,  3.61it/s]\u001b[A\n",
      " 81%| | 13/16 [00:03<00:00,  3.63it/s]\u001b[A\n",
      " 88%| | 14/16 [00:03<00:00,  3.65it/s]\u001b[A\n",
      " 94%|| 15/16 [00:04<00:00,  3.69it/s]\u001b[A\n",
      "100%|| 16/16 [00:04<00:00,  3.87it/s]\u001b[A\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "100%|| 16/16 [00:05<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
    "train_preds = predictor.predict(train_ds) \n",
    "test_preds = predictor.predict(test_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
