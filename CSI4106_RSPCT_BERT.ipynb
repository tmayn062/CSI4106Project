{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting\n",
    "The Kaggle dataset is one TSV file that will need to be formatted before training. The data must also be split into a train and test set since a seperate validation file was not provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            selftext  \n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  \n",
       "1  Did he ever say what his addiction was or is h...  \n",
       "2  Funny story. I went to college in Las Vegas. T...  \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4  Prime95 (regardless of version) and OCCT both,...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_data = pd.read_csv('rspct.tsv', sep='\\t')\n",
    "\n",
    "# Taking a look at our original dataset\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provides seperate fields for **title** and **self-text** but for the purpose of our project we want to look at an entire post (title + self-text) for the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining title and text of reddit post into one field\n",
    "rspct = pd.DataFrame({\n",
    "    'text':raw_data['title'] + \" \" + raw_data['selftext'],\n",
    "    'subreddit':raw_data['subreddit']\n",
    "}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the dataframe, every unique subreddit needs to be mapped to a numerical index in order to use them with the SimpleTransformers library. An inverse mapping is also created to easily get the subreddit name from a numerical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = raw_data['subreddit'].unique();\n",
    "label_dict = {}\n",
    "\n",
    "# Create dictionary to map subreddits to numerical values\n",
    "for i in range(len(labels)):\n",
    "    label_dict[labels[i]] = i\n",
    "\n",
    "inv_label_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing subreddits to numerical values\n",
    "for index, row in rspct.iterrows():\n",
    "    row['subreddit'] = label_dict[row['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember your command line switches... Hi ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So what was Matt \"addicted\" to? Did he ever sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Club Colors Funny story. I went to college ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not door bell, but floodlight mount height. I ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text subreddit\n",
       "0  Remember your command line switches... Hi ther...         0\n",
       "1  So what was Matt \"addicted\" to? Did he ever sa...         1\n",
       "2  No Club Colors Funny story. I went to college ...         2\n",
       "3  Not door bell, but floodlight mount height. I ...         3\n",
       "4  Worried about my 8700k small fft/data stress r...         4"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at our formatted dataset\n",
    "rspct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Set\n",
    "Now that our data has been formatted into a simple format, we can create a training set and a test set using sklearn's helper method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(rspct, test_size=0.2, shuffle=True, stratify=rspct['subreddit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are splitting the dataset into 80% for training and 20% for testing. Stratify is being used to make sure that both sets have the same distribution of subreddits to avoid balancing issues. Note that the subreddit labels are not being seperated from the post text. This is because the SimpleTransformers library requires a single dataframe with both the text and label and handles the seperation within the framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "Using the SimpleTransformers library, we can easily instantiate one of many pre-trained NLP models such as BERT. The BERT model comes in different variants such as BERT Base and BERT Large with 110M parameters and 340M parameters, respectively. To conserve memory usage and reduce training time, we are using BERT Base that has been trained on lower cased text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('bert', \n",
    "                            'bert-base-uncased', \n",
    "                            num_labels=len(label_dict), \n",
    "                            args={'reprocess_input_data': True, 'overwrite_output_dir': True, 'num_train_epochs': 1}, \n",
    "                            use_cuda=True) \n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "After training the model we can now evaluate its performance. By default the SimpleTransformers library uses MCC as a metric for classification tasks but can be also supplemented with extra metric functions. Here we are using the accuracy and classification report functions from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(test_df, \n",
    "                                                            acc=accuracy_score, \n",
    "                                                            rep=classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.9056156667582788\n",
      "Accuracy: 0.905705824284304\n",
      "Loss: 0.41924166499685794\n"
     ]
    }
   ],
   "source": [
    "print(\"MCC: %s\" %(result['mcc']))\n",
    "print(\"Accuracy: %s\" %(result['acc']))\n",
    "print(\"Loss: %s\" %(result['eval_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-at-K Results\n",
    "A metric used by the dataset curator on Kaggle was Precision-at-K Results. Precision at K measures how often the correct response was found in the first K positions of the most likely predictions. The method below has been adapted from the fast-ai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy(input, targs, k:int=5):\n",
    "    \"Computes the Top-k accuracy (target is in the top k predictions).\"\n",
    "    input = input.topk(k=k, dim=-1)[1]\n",
    "    targs = targs.unsqueeze(dim=-1).expand_as(input)\n",
    "    return (input == targs).max(dim=-1)[0].float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this method requires tensor data types, we will need to convert the model's evalutaion output into PyTorch tensors. We will also need a list of true labels from the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# Creating a numpy array of labels in our test set\n",
    "test_labels = test_df['subreddit'].to_numpy(dtype=np.int64)\n",
    "\n",
    "input = torch.from_numpy(model_outputs)\n",
    "targs = torch.from_numpy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = top_k_accuracy(input,targs,1)\n",
    "k3 = top_k_accuracy(input,targs,3)\n",
    "k5 = top_k_accuracy(input,targs,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-at-K=1 is tensor(0.9057)\n",
      "Precision-at-K=3 is tensor(0.9587)\n",
      "Precision-at-K=5 is tensor(0.9702)\n"
     ]
    }
   ],
   "source": [
    "print('Precision-at-K=1 is %s' %(k1))\n",
    "print('Precision-at-K=3 is %s' %(k3))\n",
    "print('Precision-at-K=5 is %s' %(k5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "The code below can be used to predict the parent subreddit for an arbitrary sequence of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The trained model can be loaded by running the line below\n",
    "# model = ClassificationModel('bert', \n",
    "#                            'bert-weights/', \n",
    "#                             num_labels=len(label_dict), \n",
    "#                             args={'reprocess_input_data': True, 'overwrite_output_dir': True, 'num_train_epochs': 1}, \n",
    "#                             use_cuda=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict([\"Some arbitary sentence\"])\n",
    "print(\"Prediction: %s\" %(inv_label_dict[predictions[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
